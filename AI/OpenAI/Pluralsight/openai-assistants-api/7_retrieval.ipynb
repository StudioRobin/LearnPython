{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools: Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an assistant with 'retrieval' enabled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a customer support chatbot. Use your knowledge base to best respond to customer queries.\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"retrieval\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload the 'knowledge' file that will be used for retrieval (Indicate an 'assistants' purpose)**\n",
    "\n",
    "The file I used for this demo is the one that started it all with LLMs: \"Attention Is All You Need\" by Vaswani et al.\n",
    "You can find it in: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"attentionisallyouneed.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the file to the Assistant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant.id,\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  file_ids=[file.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Thread, specify the Messaage, add it to the Thread, and Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"What are the applications of Attention in our Model?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=user_message,\n",
    "  file_ids=[file.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_PwwfGdUS1eg2JsDzW0B3BJM0',\n",
       " 'assistant_id': 'asst_KMgcINhW2I784lTr0JDLINog',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1703116088,\n",
       " 'created_at': 1703116066,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': ['file-1wLy8MwPEI56OxhHU63VYvcr'],\n",
       " 'instructions': 'You are a customer support chatbot. Use your knowledge base to best respond to customer queries.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1703116068,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_jNSq0UHUFblEJnOP8bfttcOX',\n",
       " 'tools': [{'type': 'retrieval'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_SHEexyUbXPsymbC2LBz9VQKo',\n",
       "   'assistant_id': 'asst_KMgcINhW2I784lTr0JDLINog',\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'The model described in the document utilizes multi-head attention in three distinct ways, each facilitating different aspects of sequence-to-sequence information processing:\\n\\n1. **Encoder-Decoder Attention:**\\n   - The queries in this layer come from the previous decoder layer, while the memory keys and values are derived from the output of the encoder.\\n   - This configuration allows every position in the decoder to attend over all positions in the input sequence, following the typical encoder-decoder attention mechanisms found in some sequence-to-sequence models.\\n\\n2. **Encoder Self-Attention Layers:**\\n   - In these layers, the keys, values, and queries all originate from the output of the previous encoder layer.\\n   - Each position in the encoder has the ability to attend to all positions in the previous layer of the encoder.\\n\\n3. **Decoder Self-Attention Layers:**\\n   - Positions within the decoder can attend to all positions in the decoder up to and including the current position.\\n   - To maintain the auto-regressive property of the model, leftward information flow in the decoder is prevented by masking—that is, making certain connections invalid by setting their values in the input of the softmax to negative infinity, which effectively excludes these positions from attention calculations【13†source】.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1703116078,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_PwwfGdUS1eg2JsDzW0B3BJM0',\n",
       "   'thread_id': 'thread_jNSq0UHUFblEJnOP8bfttcOX'},\n",
       "  {'id': 'msg_w9CRIpt5qAa56ROKs05pqZRf',\n",
       "   'assistant_id': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'What are the applications of Attention in our Model?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1703116065,\n",
       "   'file_ids': ['file-1wLy8MwPEI56OxhHU63VYvcr'],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'thread_id': 'thread_jNSq0UHUFblEJnOP8bfttcOX'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_SHEexyUbXPsymbC2LBz9VQKo',\n",
       " 'last_id': 'msg_w9CRIpt5qAa56ROKs05pqZRf',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id, order=\"desc\")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model described in the document utilizes multi-head attention in three distinct ways, each facilitating different aspects of sequence-to-sequence information processing:\n",
      "\n",
      "1. **Encoder-Decoder Attention:**\n",
      "   - The queries in this layer come from the previous decoder layer, while the memory keys and values are derived from the output of the encoder.\n",
      "   - This configuration allows every position in the decoder to attend over all positions in the input sequence, following the typical encoder-decoder attention mechanisms found in some sequence-to-sequence models.\n",
      "\n",
      "2. **Encoder Self-Attention Layers:**\n",
      "   - In these layers, the keys, values, and queries all originate from the output of the previous encoder layer.\n",
      "   - Each position in the encoder has the ability to attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "3. **Decoder Self-Attention Layers:**\n",
      "   - Positions within the decoder can attend to all positions in the decoder up to and including the current position.\n",
      "   - To maintain the auto-regressive property of the model, leftward information flow in the decoder is prevented by masking—that is, making certain connections invalid by setting their values in the input of the softmax to negative infinity, which effectively excludes these positions from attention calculations【13†source】.\n"
     ]
    }
   ],
   "source": [
    "print(messages.data[0].content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
