{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4805da-5c50-49ae-8110-98d9c25893db",
   "metadata": {},
   "source": [
    "# Reproducible Outputs\n",
    "Notice: This functionality is in beta at the time of the release of this course. Results may not be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9510c-ffac-4a13-aff4-6daa60e1f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f762013-9713-4810-b259-c4dc1b486819",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1be48-c3c1-4439-b5d5-43bc6d142019",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85246714-e3d3-481b-837f-cdf48fa5be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a one tweet where Xavier went on a trip to Costa Rica.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6995f-1c8f-48af-8afd-f9c1fb256494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chat_request(prompt):\n",
    "    chat_messages.append({\"role\": \"system\",\"content\": \"You are a useful assistant that generates stories.\"})\n",
    "    chat_messages.append({\"role\": \"user\",\"content\": prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages = chat_messages,\n",
    "        seed=4235,\n",
    "        temperature=0\n",
    "    )\n",
    "    # Append the response to messages\n",
    "    response_content = response.choices[0].message.content\n",
    "    chat_messages.append({\"role\": \"assistant\",\"content\": response_content})\n",
    "    \n",
    "    print(\"Fingerprint: \" + response.system_fingerprint)\n",
    "    print(response_content)\n",
    "    \n",
    "    # Return the response content\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f16dd-bc6e-40b3-a013-f72601744d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base story:/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7a126-7b20-47bc-984d-9af39350c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_story = process_chat_request(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885a5ae-4602-4dd1-8541-328e3f30cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    new_story = process_chat_request(prompt)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if (base_story == new_story):\n",
    "        print(\"Consistent output\")\n",
    "    else:\n",
    "        print(\"Non-reproducible output found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
