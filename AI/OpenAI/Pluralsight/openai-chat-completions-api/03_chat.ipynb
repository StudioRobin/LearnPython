{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4805da-5c50-49ae-8110-98d9c25893db",
   "metadata": {},
   "source": [
    "# Using the Chat Completions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9510c-ffac-4a13-aff4-6daa60e1f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f762013-9713-4810-b259-c4dc1b486819",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85246714-e3d3-481b-837f-cdf48fa5be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "chat_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe91826-2a4d-4ab1-a4bb-be2fa29a2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chat_request(prompt):\n",
    "    chat_messages.append({\"role\": \"user\",\"content\": prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = chat_messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    # Append the response to messages\n",
    "    response_content = response.choices[0].message.content\n",
    "    chat_messages.append({\"role\": \"assistant\",\"content\": response_content})\n",
    "     \n",
    "    print(json.dumps(chat_messages, indent=2))\n",
    "    \n",
    "    # Return the response content\n",
    "    return response_content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453ae49-16b0-4eb3-97f1-d9cfada7c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the system message\n",
    "system_message = \"You are a helpful assistant\"\n",
    "chat_messages = [{\"role\": \"system\", \"content\": system_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6995f-1c8f-48af-8afd-f9c1fb256494",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, how can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd3955-69e6-4adc-aa67-c21239a68290",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:  \n",
    "    print(\"Prompt: \\n\")\n",
    "    user_prompt = input()\n",
    "    response = process_chat_request(user_prompt)\n",
    "    print(\"Response: \\n\" + response)\n",
    "    \n",
    "    if user_prompt.lower() in [\"bye\", \"exit\", \"quit\"]:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
